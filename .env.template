# MAGPIE Multi-Agent System Configuration Template
# Copy this file to .env and fill in your actual values
#
# This configuration supports:
# - Master Coordinator (intelligent routing)
# - Engineering Process Procedure Agent (aviation MRO queries with Databricks)
# - General Chat Agent (conversations & advice)
# - Multi-Model Support (4 different Azure models)

# Azure OpenAI API Configuration
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-12-01-preview

# =============================================================================
# MULTI-MODEL CONFIGURATION
# =============================================================================
# All models use the same Azure endpoint, API key, and API version
# Choose from: gpt-4.1, gpt-4.1-mini, gpt-4.1-nano, DeepSeek-R1-0528

# Available Models Configuration
# Format: azure/<deployment_name>
AVAILABLE_MODELS_GPT41=azure/gpt-4.1
AVAILABLE_MODELS_GPT41_MINI=azure/gpt-4.1-mini
AVAILABLE_MODELS_GPT41_NANO=azure/gpt-4.1-nano
AVAILABLE_MODELS_DEEPSEEK=azure/DeepSeek-R1-0528

# Legacy Configuration (for backward compatibility)
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4.1
AZURE_OPENAI_MODEL=azure/gpt-4.1

# =============================================================================
# AGENT-SPECIFIC MODEL CONFIGURATION
# =============================================================================
# Each agent can be configured to use a specific model
# If not specified, will use DEFAULT_LLM_MODEL

# Master Coordinator - Handles routing decisions (needs strong reasoning)
MASTER_COORDINATOR_MODEL=azure/gpt-4.1

# Engineering Process Procedure Agent - Complex technical queries
ENGINEERING_PROCESS_AGENT_MODEL=azure/DeepSeek-R1-0528

# Query Enhancement Sub-Agent - Focused enhancement tasks
QUERY_ENHANCEMENT_AGENT_MODEL=azure/gpt-4.1-nano

# Databricks Query Sub-Agent - Technical query processing
DATABRICKS_QUERY_AGENT_MODEL=azure/gpt-4.1

# General Chat Agent - Casual conversation (cost-effective)
GENERAL_CHAT_AGENT_MODEL=azure/gpt-4.1-mini

# =============================================================================
# GLOBAL CONFIGURATION
# =============================================================================

# ADK Configuration
# Disable Vertex AI to use direct API keys
GOOGLE_GENAI_USE_VERTEXAI=False

# Databricks Configuration (for Engineering Process Procedure Agent and MCP Server)
# Required for service principal authentication to Databricks APIs
#
# How to obtain these values:
# 1. DATABRICKS_WORKSPACE_URL: Your Databricks workspace URL (e.g., https://adb-123456789.11.azuredatabricks.net)
# 2. DATABRICKS_TENANT_ID: Azure AD tenant ID where your service principal is registered
# 3. DATABRICKS_CLIENT_ID: Service principal application (client) ID
# 4. DATABRICKS_CLIENT_SECRET: Service principal client secret
#
# Note: The service principal must have access to Databricks APIs and serving endpoints
DATABRICKS_WORKSPACE_URL=https://your-databricks-workspace.azuredatabricks.net
DATABRICKS_TENANT_ID=your_azure_tenant_id
DATABRICKS_CLIENT_ID=your_service_principal_client_id
DATABRICKS_CLIENT_SECRET=your_service_principal_secret

# Optional: Default warehouse for SQL operations
DATABRICKS_WAREHOUSE_ID=your_warehouse_id

# Default Model Configuration
DEFAULT_LLM_MODEL=azure/gpt-4.1
DEFAULT_TEMPERATURE=0.2
DEFAULT_MAX_TOKENS=1000

# Model Selection Strategy
# Options: agent_specific, default, environment
# - agent_specific: Use agent-specific model configurations above
# - default: Use DEFAULT_LLM_MODEL for all agents
# - environment: Use AZURE_OPENAI_MODEL for all agents (legacy)
MODEL_SELECTION_STRATEGY=agent_specific

# Logging Configuration
AGENT_LOG_LEVEL=INFO
LITELLM_DEBUG=False
